#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯å‘é‡æ£€ç´¢åŠŸèƒ½
ä½¿ç”¨æ–¹æ³•: python quick_test.py
"""

import sys
import os
import numpy as np
from pymilvus import MilvusClient

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/autodl-tmp/multimodel_fasion_retrieval')
from data_embedding.model_vectorization import FashionEmbeddingModel
from vector_db.retrieval_util import (
    search_text_embedding, 
    search_image_embedding, 
    hybrid_search_weighted
)

def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¿«é€Ÿæµ‹è¯•å‘é‡æ£€ç´¢åŠŸèƒ½")
    
    # 1. è¿æ¥Milvus
    try:
        uri = "https://in03-338d6950a393b2c.serverless.gcp-us-west1.cloud.zilliz.com"
        token = "xxxxxxx"
        
        client = MilvusClient(
            uri=uri,
            token=token
        )
        print("âœ… Milvusè¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Milvusè¿æ¥å¤±è´¥: {e}")
        return
    
    # 3. åŠ è½½æ¨¡å‹
    try:
        model_path = "../../../training_results_20250705_165112/model_weights/best_model.pth"
        processor_path = "/root/autodl-fs/blip-image-captioning-base/"
        model = FashionEmbeddingModel(model_path, processor_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # 4. ç®€å•æµ‹è¯•
    try:
        print("\nğŸ“ æµ‹è¯•æ–‡æœ¬æ£€ç´¢...")
        query_text = "red dress"
        query_emb = model.encode_text(query_text)
        
        # ä½¿ç”¨retrieval_utilä¸­çš„å‡½æ•°è¿›è¡Œæ–‡æœ¬æ£€ç´¢
        results = search_text_embedding(client, query_emb, top_k=2)
        print(f"æŸ¥è¯¢: '{query_text}' -> æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        print(results)
        
        print("\nğŸ–¼ï¸  æµ‹è¯•å›¾ç‰‡æ£€ç´¢...")
        # ä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹å›¾ç‰‡è·¯å¾„
        test_img_path = "../../../dataset/DeepFashion-MultiModal/selected_images/MEN-Denim-id_00000089-28_1_front.jpg"
        if os.path.exists(test_img_path):
            query_emb = model.encode_image(test_img_path)
            
            # ä½¿ç”¨retrieval_utilä¸­çš„å‡½æ•°è¿›è¡Œå›¾ç‰‡æ£€ç´¢
            results = search_image_embedding(client, query_emb, top_k=2)
            print(f"æŸ¥è¯¢å›¾ç‰‡: {test_img_path} -> æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            print(results)
        else:
            print(f"âš ï¸  æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_img_path}")
        
        print("\nğŸ”„ æµ‹è¯•æ··åˆæ£€ç´¢...")
        if os.path.exists(test_img_path):
            img_emb = model.encode_image(test_img_path)
            text_emb = model.encode_text("blue jeans")
            
            # ä½¿ç”¨retrieval_utilä¸­çš„å‡½æ•°è¿›è¡Œæ··åˆæ£€ç´¢
            results = hybrid_search_weighted(client, img_emb, text_emb, alpha=0.5, top_k=2)
            print(results[0])
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    finally:
        try:
            print("âœ… æµ‹è¯•å®Œæˆ")
        except:
            pass

if __name__ == "__main__":
    quick_test() 